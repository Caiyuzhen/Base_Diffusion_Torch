{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DiffusionPipeline\n",
    "import torch\n",
    "\n",
    "# æ£€æŸ¥æ˜¯å¦å¯ä»¥ä½¿ç”¨ MPSï¼ˆApple çš„ GPU åŠ é€Ÿï¼‰\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "print(\"æ£€æŸ¥ Mac mps æ˜¯å¦å¯ç”¨ï½ï½ï½\")\n",
    "print(torch.backends.mps.is_available())  # æ£€æŸ¥ MPS æ˜¯å¦å¯ç”¨\n",
    "print(torch.backends.mps.is_built())      # æ£€æŸ¥ PyTorch æ˜¯å¦æ„å»ºäº† MPS æ”¯æŒ\n",
    "\n",
    "\n",
    "# ä»é¢„è®­ç»ƒæ¨¡å‹åŠ è½½ DiffusionPipeline\n",
    "pipeline = DiffusionPipeline.from_pretrained(\n",
    "    'model/diffsion_from_scratch.params', safety_checker=None\n",
    ")\n",
    "\n",
    "\n",
    "# ã€å·¥å…·ç±»ã€‘è·å–è°ƒåº¦å™¨å’Œåˆ†è¯å™¨\n",
    "scheduler = pipeline.scheduler # scheduler æ˜¯å¾€å›¾ç‰‡ä¸­æ·»åŠ å™ªå£°çš„æ–¹æ³•\n",
    "tokenizer = pipeline.tokenizer\n",
    "\n",
    "# é‡Šæ”¾ pipeline èµ„æº\n",
    "del pipeline\n",
    "\n",
    "# æ‰“å°è®¾å¤‡ã€è°ƒåº¦å™¨å’Œåˆ†è¯å™¨\n",
    "device, scheduler, tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ğŸš€ğŸš€ ç”Ÿæˆå‡½æ•°, ç”¨äºæµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹, å…¥å‚æ˜¯ä¸€æ®µæ–‡æœ¬\n",
    "\n",
    "@torch.no_grad()  # ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼Œä»¥èŠ‚çœå†…å­˜å’ŒåŠ é€Ÿæ¨ç†\n",
    "def generate(text):\n",
    "    # è¯ç¼–ç \n",
    "    # å°†è¾“å…¥çš„æ–‡æœ¬è½¬æ¢ä¸ºç¼–ç åçš„å¼ é‡ï¼Œå½¢çŠ¶ä¸º [1, 77]\n",
    "    # ç¬¬ä¸€æ¬¡ç¼–ç \n",
    "    pos = tokenizer(text,\n",
    "                    padding='max_length',  # å¯¹æ–‡æœ¬è¿›è¡Œå¡«å……ï¼Œä½¿å…¶è¾¾åˆ°æœ€å¤§é•¿åº¦\n",
    "                    max_length=77,         # æœ€å¤§é•¿åº¦ä¸º 77 ä¸ªæ ‡è®°\n",
    "                    truncation=True,       # å¦‚æœæ–‡æœ¬è¿‡é•¿åˆ™æˆªæ–­\n",
    "                    return_tensors='pt'    # è¿”å› PyTorch å¼ é‡\n",
    "                    ).input_ids.to(device) # å°†å¼ é‡ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡ï¼ˆå¦‚ GPUï¼‰\n",
    "\n",
    "    # ç¬¬äºŒæ¬¡ç¼–ç  (è´Ÿé‡‡æ ·)\n",
    "    # ç”Ÿæˆä¸€ä¸ªç©ºçš„æ–‡æœ¬ç¼–ç ä½œä¸ºè´Ÿæ ·æœ¬ï¼Œå½¢çŠ¶ä¸º [1, 77]\n",
    "    neg = tokenizer('',\n",
    "                    padding='max_length',\n",
    "                    max_length=77,\n",
    "                    truncation=True,\n",
    "                    return_tensors='pt'\n",
    "                    ).input_ids.to(device)\n",
    "\n",
    "    # ä½¿ç”¨ç¼–ç å™¨å¯¹æ­£ã€è´Ÿæ ·æœ¬è¿›è¡Œç¼–ç \n",
    "    # å½¢çŠ¶ä» [1, 77] è½¬æ¢ä¸º [1, 77, 768]\n",
    "    pos = encoder(pos)\n",
    "    neg = encoder(neg)\n",
    "\n",
    "    # å°†æ­£ã€è´Ÿæ ·æœ¬çš„ç¼–ç ç»“æœæ‹¼æ¥åœ¨ä¸€èµ·\n",
    "    # å½¢çŠ¶ä» [1, 77, 768] + [1, 77, 768] -> [2, 77, 768]\n",
    "    out_encoder = torch.cat((neg, pos), dim=0)\n",
    "\n",
    "    # ğŸ‘‡ğŸ‘‡ åŸæœ¬æ˜¯è¦æ‹¿ä¸€å¼ å›¾ç‰‡çš„, ä½†æˆ‘ä»¬æ˜¯æ–‡ç”Ÿå›¾çš„ä»»åŠ¡, å› æ­¤å°±ã€éšæœºç”Ÿæˆä¸€å¼ å™ªå£°å›¾ç‰‡ã€‘å°±å¥½äº†\n",
    "    # ä»éšæœºå™ªå£°å¼€å§‹ç”Ÿæˆ VAE çš„å‹ç¼©å›¾åƒè¡¨ç¤º\n",
    "    out_vae = torch.randn(1, 4, 64, 64, device=device)  # åˆå§‹å™ªå£°ï¼Œå½¢çŠ¶ä¸º [1, 4, 64, 64]\n",
    "\n",
    "\n",
    "    # ã€ğŸš€ é™å™ª 50 æ¬¡ã€‘è®¾ç½®æ—¶é—´æ­¥é•¿ï¼Œç”Ÿæˆè¿‡ç¨‹ä¸­çš„æ­¥æ•°ä¸º 50ï¼Œä¸€èˆ¬ä» 980 é€’å‡åˆ° 0\n",
    "    scheduler.set_timesteps(50, device=device)\n",
    "\n",
    "    # è®© time é€æ¸é™å™ª, ä» 999 æ¥è¿‘äº 0 \n",
    "    for time in scheduler.timesteps:\n",
    "        # ç»™å›¾åƒæ·»åŠ å™ªå£°ï¼Œç”¨äºè¾“å…¥ U-Net\n",
    "        # å°†å›¾åƒå’Œå™ªå£°æ‹¼æ¥åœ¨ä¸€èµ·ï¼Œå½¢çŠ¶ä» [1, 4, 64, 64] -> [2, 4, 64, 64]\n",
    "        noise = torch.cat((out_vae, out_vae), dim=0) # ğŸ‘ˆ æ­£è´Ÿä¸¤ä»½ out_vae , å¯¹åº”æ–‡å­—çš„ pos è·Ÿ neg\n",
    "        noise = scheduler.scale_model_input(noise, time)  # ç¼©æ”¾è¾“å…¥ï¼Œä»¥é€‚åº”å½“å‰æ—¶é—´æ­¥é•¿\n",
    "\n",
    "        # ä½¿ç”¨ U-Net é¢„æµ‹å™ªå£°\n",
    "        # ã€ğŸ”¥ ä½¿ç”¨ Unet å¯¹è¿™å¼ ç‰¹å¾å›¾è¿›è¡Œé™å™ªã€‘è¾“å…¥å¸¦å™ªå£°çš„å›¾åƒå’Œæ–‡æœ¬ç¼–ç ï¼Œè¾“å‡ºå™ªå£°é¢„æµ‹ï¼Œå½¢çŠ¶ä¸º [2, 4, 64, 64]\n",
    "        pred_noise = unet(out_vae=noise, out_encoder=out_encoder, time=time)\n",
    "\n",
    "        # ä»ã€æ­£æ ·æœ¬çš„é¢„æµ‹ã€‘ä¸­å‡å»ã€è´Ÿæ ·æœ¬çš„é¢„æµ‹ã€‘ï¼Œå¾—åˆ°æœ€ç»ˆçš„å™ªå£°é¢„æµ‹\n",
    "        # å½¢çŠ¶ä» [2, 4, 64, 64] -> [1, 4, 64, 64]\n",
    "        pred_noise = pred_noise[0] + 7.5 * (pred_noise[1] - pred_noise[0])\n",
    "\n",
    "        # ä½¿ç”¨ scheduler æ›´æ–°å›¾åƒ, é‡æ–°æ·»åŠ å™ªå£°ç„¶åè¿›è¡Œä¸‹ä¸€è½®çš„é™å™ª, åå¤ 50 æ­¥ ï¼ˆæ¯æ¬¡æ·»åŠ çš„å™ªå£°ä¼šè¶Šæ¥è¶Šä½ï¼‰\n",
    "        # å½¢çŠ¶ä¿æŒ [1, 4, 64, 64]\n",
    "        out_vae = scheduler.step(pred_noise, time, out_vae).prev_sample\n",
    "\n",
    "\n",
    "    # ã€ğŸ”¥ æ‹¿è¿™å¼ ç‰¹å¾å›¾æ”¾åˆ° vae ä¸­è¿›è¡Œæœ€ç»ˆçš„è§£ç ã€‘ä» VAE çš„å‹ç¼©è¡¨ç¤ºæ¢å¤æˆå›¾åƒ ___________________________________________\n",
    "    out_vae = 1 / 0.18215 * out_vae  # å°†å›¾åƒæ”¾å¤§åˆ°åŸå§‹å°ºåº¦\n",
    "    # ä½¿ç”¨ VAE è§£ç å™¨å°†å›¾åƒä» [1, 4, 64, 64] æ¢å¤åˆ° [1, 3, 512, 512]\n",
    "    image = vae.decoder(out_vae)\n",
    "\n",
    "    # å°†å¼ é‡è½¬æ¢ä¸ºå›¾ç‰‡æ•°æ®\n",
    "    image = image.cpu()               # å°†å¼ é‡ç§»å› CPU\n",
    "    image = (image + 1) / 2           # å°†åƒç´ å€¼ä» [-1, 1] èŒƒå›´ç¼©æ”¾åˆ° [0, 1] èŒƒå›´\n",
    "    image = image.clamp(0, 1)         # å°†åƒç´ å€¼é™åˆ¶åœ¨ [0, 1] èŒƒå›´å†…\n",
    "    image = image.permute(0, 2, 3, 1) # è°ƒæ•´ç»´åº¦é¡ºåºï¼Œä» [batch, channels, height, width] -> [batch, height, width, channels]\n",
    "    return image.numpy()[0]           # å°†å¼ é‡è½¬æ¢ä¸º NumPy æ•°ç»„å¹¶è¿”å›ç¬¬ä¸€å¼ å›¾ç‰‡\n",
    "\n",
    "# è°ƒç”¨ generate å‡½æ•°ç”Ÿæˆå›¾åƒï¼Œå¹¶æŸ¥çœ‹ç”Ÿæˆå›¾åƒçš„å½¢çŠ¶\n",
    "generate('a drawing of a star with a jewel in the center').shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”»å›¾å‡½æ•°, å±•ç¤ºå‡ å¼ å›¾\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show():\n",
    "    texts = [\n",
    "        'a drawing of a star with a jewel in the center',  #å®çŸ³æµ·æ˜Ÿ\n",
    "        'a drawing of a woman in a red cape',  #è¿·å”‡å§\n",
    "        'a drawing of a dragon sitting on its hind legs',  #è‚¥å¤§\n",
    "        'a drawing of a blue sea turtle holding a rock',  #æ‹‰æ™®æ‹‰æ–¯\n",
    "        'a blue and white bird with its wings spread',  #æ€¥å†»é¸Ÿ\n",
    "        'a blue and white stuffed animal sitting on top of a white surface',  #å¡æ¯”å…½\n",
    "    ]\n",
    "\n",
    "    images = [generate(i) for i in texts]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i in range(6):\n",
    "        plt.subplot(2, 3, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# ä¼šå±•ç¤ºã€é¢„è®­ç»ƒçš„æ¨¡å‹æ‰€ç”»å‡ºæ¥çš„å›¾ã€‘\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "\n",
    "# ã€ğŸ”¥ä½¿ç”¨æˆ‘ä»¬è‡ªå·±è®­ç»ƒå¥½çš„æ¨¡å‹åŠ è½½æ•°æ®ã€‘\n",
    "#åŒ…è£…ç±»\n",
    "class Model(PreTrainedModel):\n",
    "    config_class = PretrainedConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.unet = unet.to('cpu')\n",
    "\n",
    "\n",
    "#åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹\n",
    "unet = Model.from_pretrained('diffsion_from_scratch.unet').unet\n",
    "unet.eval().to(device)\n",
    "\n",
    "show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
