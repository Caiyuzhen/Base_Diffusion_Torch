{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ËøêË°åÁéØÂ¢É\n",
    "`diffusers == 0.121`\n",
    "\n",
    "# VAE ÁöÑ‰ΩúÁî®\n",
    "VAE ÂèØ‰ª•‰ªéÊΩúÂú®Á©∫Èó¥Ôºàlatent spaceÔºâ‰∏≠ÁîüÊàêÊñ∞ÁöÑÊ†∑Êú¨„ÄÇÈÄöËøáÂ≠¶‰π†Êï∞ÊçÆÁöÑÊΩúÂú®Ë°®Á§∫ÔºåVAE ÂèØ‰ª•ÁîüÊàê‰∏éËÆ≠ÁªÉÊï∞ÊçÆÁõ∏‰ººÁöÑÊñ∞Êï∞ÊçÆ„ÄÇ‰æãÂ¶ÇÔºåÂèØ‰ª•Áî® VAE ÁîüÊàêÊñ∞\n",
    "ÁöÑÂõæÂÉè„ÄÅÈü≥È¢ë„ÄÅÊñáÊú¨Á≠â"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 10, 10])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# ÂÆö‰πâÊÆãÂ∑ÆËøûÊé•Â±ÇÁöÑÁ±ª\n",
    "class Resnet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "\n",
    "        # ÂÆö‰πâ‰∏Ä‰∏™Â∫èÂàóÂåñÁöÑÁ•ûÁªèÁΩëÁªúÊ®°Âùó\n",
    "        self.s = torch.nn.Sequential(\n",
    "            torch.nn.GroupNorm(num_groups=32,  # ÂΩí‰∏ÄÂåñÂ±ÇÔºåÂàÜÊàê32ÁªÑ\n",
    "                               num_channels=dim_in,  # ËæìÂÖ•ÈÄöÈÅìÊï∞\n",
    "                               eps=1e-6,  # Èò≤Ê≠¢Èô§Èõ∂\n",
    "                               affine=True),  # ÂÖÅËÆ∏Áº©ÊîæÂíåÂπ≥Áßª\n",
    "            torch.nn.SiLU(),  # SiLUÊøÄÊ¥ªÂáΩÊï∞\n",
    "            torch.nn.Conv2d(dim_in,  # ËæìÂÖ•ÈÄöÈÅìÊï∞\n",
    "                            dim_out,  # ËæìÂá∫ÈÄöÈÅìÊï∞\n",
    "                            kernel_size=3,  # Âç∑ÁßØÊ†∏Â§ßÂ∞è\n",
    "                            stride=1,  # Ê≠•ÂπÖ\n",
    "                            padding=1),  # Â°´ÂÖÖÔºå‰ΩøÂæóËæìÂá∫Â§ßÂ∞è‰∏éËæìÂÖ•Áõ∏Âêå\n",
    "            torch.nn.GroupNorm(num_groups=32,  # ÂΩí‰∏ÄÂåñÂ±ÇÔºåÂàÜÊàê32ÁªÑ\n",
    "                               num_channels=dim_out,  # ËæìÂá∫ÈÄöÈÅìÊï∞\n",
    "                               eps=1e-6,  # Èò≤Ê≠¢Èô§Èõ∂\n",
    "                               affine=True),  # ÂÖÅËÆ∏Áº©ÊîæÂíåÂπ≥Áßª\n",
    "            torch.nn.SiLU(),  # SiLUÊøÄÊ¥ªÂáΩÊï∞\n",
    "            torch.nn.Conv2d(dim_out,  # ËæìÂÖ•ÈÄöÈÅìÊï∞\n",
    "                            dim_out,  # ËæìÂá∫ÈÄöÈÅìÊï∞\n",
    "                            kernel_size=3,  # Âç∑ÁßØÊ†∏Â§ßÂ∞è\n",
    "                            stride=1,  # Ê≠•ÂπÖ\n",
    "                            padding=1),  # Â°´ÂÖÖÔºå‰ΩøÂæóËæìÂá∫Â§ßÂ∞è‰∏éËæìÂÖ•Áõ∏Âêå\n",
    "        )\n",
    "\n",
    "        # Â¶ÇÊûúËæìÂÖ•ÂíåËæìÂá∫ÁöÑÈÄöÈÅìÊï∞‰∏ç‰∏ÄËá¥ÔºåÂàô‰ΩøÁî®1x1Âç∑ÁßØË∞ÉÊï¥ËæìÂÖ•ÁöÑÈÄöÈÅìÊï∞\n",
    "        self.res = None\n",
    "        if dim_in != dim_out:\n",
    "            self.res = torch.nn.Conv2d(dim_in,  # ËæìÂÖ•ÈÄöÈÅìÊï∞\n",
    "                                       dim_out,  # ËæìÂá∫ÈÄöÈÅìÊï∞\n",
    "                                       kernel_size=1,  # 1x1Âç∑ÁßØÊ†∏\n",
    "                                       stride=1,  # Ê≠•ÂπÖ\n",
    "                                       padding=0)  # Êó†Â°´ÂÖÖ\n",
    "\n",
    "    def forward(self, x):\n",
    "        # xÁöÑÂΩ¢Áä∂‰∏∫ [batch_size, channels, height, width]ÔºåËøôÈáå‰∏∫ [1, 128, 10, 10]\n",
    "        res = x  # ‰øùÂ≠òËæìÂÖ•Ôºå‰Ωú‰∏∫ÊÆãÂ∑ÆÈ°π\n",
    "        if self.res:\n",
    "            # Â¶ÇÊûúÈúÄË¶ÅË∞ÉÊï¥ÈÄöÈÅìÊï∞Ôºå‰ΩøÁî®1x1Âç∑ÁßØË∞ÉÊï¥ÊÆãÂ∑ÆÁöÑÂΩ¢Áä∂‰∏∫ [1, 256, 10, 10]\n",
    "            res = self.res(x)\n",
    "\n",
    "        # ËÆ°ÁÆó‰∏ªÂàÜÊîØÁöÑËæìÂá∫ÔºåÂπ∂‰∏éÊÆãÂ∑ÆÁõ∏Âä†\n",
    "        # ‰∏ªÂàÜÊîØÁöÑËæìÂá∫ÂΩ¢Áä∂‰∏∫ [1, 256, 10, 10]\n",
    "        return res + self.s(x)  # ÊÆãÂ∑ÆÁõ∏Âä†ÂêéÁöÑËæìÂá∫\n",
    "\n",
    "# ÊµãËØï Resnet Á±ªÔºåËæìÂÖ•ÂΩ¢Áä∂‰∏∫ [1, 128, 10, 10]ÔºåÊúüÊúõËæìÂá∫ÂΩ¢Áä∂‰∏∫ [1, 256, 10, 10]\n",
    "Resnet(128, 256)(torch.randn(1, 128, 10, 10)).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 64, 64])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAE Ëá™Ê≥®ÊÑèÂäõÂ±ÇÁ±ª(ÂçïÂ§¥Ëá™Ê≥®ÊÑèÂäõ)\n",
    "class Atten(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # norm Â±Ç\n",
    "        self.norm = torch.nn.GroupNorm(num_channels=512,\n",
    "                                       num_groups=32,\n",
    "                                       eps=1e-6,\n",
    "                                       affine=True)\n",
    "\n",
    "        \"\"\"\n",
    "        Âú®Ê≥®ÊÑèÂäõÊú∫Âà∂‰∏≠ÔºåÊàë‰ª¨ÂØπÊØè‰∏™ËæìÂÖ•ÂÖÉÁ¥†Ôºà‰æãÂ¶ÇÂè•Â≠ê‰∏≠ÁöÑ‰∏Ä‰∏™ÂçïËØçÔºâÁîüÊàê‰∏â‰∏™ÂêëÈáèÔºö\n",
    "            Êü•ËØ¢ÂêëÈáè (Query Vector, Q)\n",
    "            ÈîÆÂêëÈáè (Key Vector, K)\n",
    "            ÂÄºÂêëÈáè (Value Vector, V)\n",
    "        \"\"\"\n",
    "        self.q = torch.nn.Linear(512, 512)\n",
    "        self.k = torch.nn.Linear(512, 512)\n",
    "        self.v = torch.nn.Linear(512, 512)\n",
    "        self.out = torch.nn.Linear(512, 512)\n",
    "\n",
    "    # ÂçïÂ§¥, Êó† mask\n",
    "    def forward(self, x):\n",
    "        #x -> [1, 512, 64, 64]\n",
    "        res = x\n",
    "\n",
    "        #norm,Áª¥Â∫¶‰∏çÂèò\n",
    "        #[1, 512, 64, 64]\n",
    "        x = self.norm(x)\n",
    "\n",
    "        #[1, 512, 64, 64] -> [1, 512, 4096] -> [1, 4096, 512]\n",
    "        x = x.flatten(start_dim=2).transpose(1, 2)\n",
    "\n",
    "        #Á∫øÊÄßËøêÁÆó,Áª¥Â∫¶‰∏çÂèò\n",
    "        #[1, 4096, 512]\n",
    "        q = self.q(x)\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "\n",
    "        #[1, 4096, 512] -> [1, 512, 4096]\n",
    "        k = k.transpose(1, 2)\n",
    "\n",
    "        #[1, 4096, 512] * [1, 512, 4096] -> [1, 4096, 4096]\n",
    "        #0.044194173824159216 = 1 / 512**0.5\n",
    "        \n",
    "\n",
    "        # ÁÖßÁêÜÊù•ËØ¥Â∫îËØ•ÊòØÁ≠â‰ª∑ÁöÑ,‰ΩÜÊòØÂç¥ÊúâÂæàÂ∞èÁöÑËØØÂ∑Æ\n",
    "        # atten = q.bmm(k) * 0.044194173824159216\n",
    "        atten = torch.baddbmm(torch.empty(1, 4096, 4096, device=q.device),\n",
    "                              q,\n",
    "                              k,\n",
    "                              beta=0,\n",
    "                              alpha=0.044194173824159216)\n",
    "\n",
    "        atten = torch.softmax(atten, dim=2)\n",
    "\n",
    "        #[1, 4096, 4096] * [1, 4096, 512] -> [1, 4096, 512]\n",
    "        atten = atten.bmm(v)\n",
    "\n",
    "        #Á∫øÊÄßËøêÁÆó,Áª¥Â∫¶‰∏çÂèò\n",
    "        #[1, 4096, 512]\n",
    "        atten = self.out(atten)\n",
    "\n",
    "        #[1, 4096, 512] -> [1, 512, 4096] -> [1, 512, 64, 64]\n",
    "        atten = atten.transpose(1, 2).reshape(-1, 512, 64, 64)\n",
    "\n",
    "        # ÊÆãÂ∑ÆËøûÊé•,Áª¥Â∫¶‰∏çÂèò\n",
    "        # [1, 512, 64, 64]\n",
    "        atten = atten + res\n",
    "\n",
    "        return atten\n",
    "\n",
    "\n",
    "Atten()(torch.randn(1, 512, 64, 64)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 0.],\n",
       "          [1., 1., 1., 1., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0.]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Â∑•ÂÖ∑Â±Ç\n",
    "class Pad(torch.nn.Module):\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ÁªôÊï∞ÊçÆÁöÑÊúÄÂè≥ËæπË∑üÊúÄ‰∏ãËæπÂ¢ûÂä†‰∏ÄË°åË∑ü‰∏ÄÂàóÁöÑ 0\n",
    "        return torch.nn.functional.pad(x, (0, 1, 0, 1),\n",
    "                                       mode='constant',\n",
    "                                       value=0)\n",
    "\n",
    "\n",
    "Pad()(torch.ones(1, 2, 5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# VAE Ê®°ÂûãÁ±ª\n",
    "# ÂàÜ‰∏∫ encode Ë∑ü decode ‰∏§‰∏™ÂèÇÊï∞\n",
    "\n",
    "import torch\n",
    "\n",
    "# ÂÆö‰πâÂèòÂàÜËá™ÁºñÁ†ÅÂô®ÔºàVAEÔºâÊ®°ÂûãÁ±ªÔºåÂåÖÂê´ÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®\n",
    "class VAE(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # ÂÆö‰πâÁºñÁ†ÅÂô®ÈÉ®ÂàÜ\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            # ËæìÂÖ•Â±ÇÔºöÂç∑ÁßØÊìç‰ΩúÔºåÂ∞ÜËæìÂÖ•ÂõæÂÉèÁöÑÈÄöÈÅìÊï∞‰ªé3Âèò‰∏∫128\n",
    "            torch.nn.Conv2d(3, 128, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            # ‰∏ãÈááÊ†∑ÂíåÁâπÂæÅÊèêÂèñÈÉ®ÂàÜÔºàÂ§öÂ±Ç ResNet Ê®°ÂùóÂíåÂç∑ÁßØ‰∏ãÈááÊ†∑Ôºâ\n",
    "            torch.nn.Sequential(\n",
    "                Resnet(128, 128),  # ResNet ÊÆãÂ∑ÆÊ®°ÂùóÔºåËæìÂÖ•ÂíåËæìÂá∫ÈÄöÈÅìÂùá‰∏∫128\n",
    "                Resnet(128, 128),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "                torch.nn.Sequential(\n",
    "                    Pad(),  # Â°´ÂÖÖÊìç‰Ωú\n",
    "                    torch.nn.Conv2d(128, 128, 3, stride=2, padding=0),  # Âç∑ÁßØ‰∏ãÈááÊ†∑ÔºåËæìÂá∫ÁâπÂæÅÂõæÂ∞∫ÂØ∏ÂáèÂçä\n",
    "                ),\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                Resnet(128, 256),  # ResNet Ê®°ÂùóÔºåÈÄöÈÅìÊï∞‰ªé128Â¢ûÂä†Âà∞256\n",
    "                Resnet(256, 256),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "                torch.nn.Sequential(\n",
    "                    Pad(),\n",
    "                    torch.nn.Conv2d(256, 256, 3, stride=2, padding=0),  # ÂÜçÊ¨°‰∏ãÈááÊ†∑\n",
    "                ),\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                Resnet(256, 512),  # ResNet Ê®°ÂùóÔºåÈÄöÈÅìÊï∞‰ªé256Â¢ûÂä†Âà∞512\n",
    "                Resnet(512, 512),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "                torch.nn.Sequential(\n",
    "                    Pad(),\n",
    "                    torch.nn.Conv2d(512, 512, 3, stride=2, padding=0),  # ÂÜçÊ¨°‰∏ãÈááÊ†∑\n",
    "                ),\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                Resnet(512, 512),  # ‰øùÊåÅÈÄöÈÅìÊï∞‰∏∫512ÁöÑ ResNet Ê®°Âùó\n",
    "                Resnet(512, 512),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "            ),\n",
    "\n",
    "            # ‰∏≠Èó¥Â±ÇÔºöÂ¢ûÂä†Ê≥®ÊÑèÂäõÊú∫Âà∂\n",
    "            torch.nn.Sequential(\n",
    "                Resnet(512, 512),  # ResNet Ê®°Âùó\n",
    "                Atten(),  # Ê≥®ÊÑèÂäõÊú∫Âà∂Ê®°Âùó\n",
    "                Resnet(512, 512),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "            ),\n",
    "\n",
    "            # ËæìÂá∫Â±ÇÔºöÊ†áÂáÜÂåñÂíåÂç∑ÁßØÊìç‰Ωú\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.GroupNorm(num_channels=512, num_groups=32, eps=1e-6),  # ÁªÑÂΩí‰∏ÄÂåñ\n",
    "                torch.nn.SiLU(),  # SiLU ÊøÄÊ¥ªÂáΩÊï∞\n",
    "                torch.nn.Conv2d(512, 8, 3, padding=1),  # Â∞ÜÁâπÂæÅÂõæÈÄöÈÅìÊï∞Èôç‰∏∫8\n",
    "            ),\n",
    "\n",
    "            # ÊúÄÂêé‰∏ÄÂ±ÇÔºåÁî®‰∫éÁîüÊàêÊ≠£ÊÄÅÂàÜÂ∏ÉÁöÑÂùáÂÄºÂíåÊñπÂ∑Æ\n",
    "            torch.nn.Conv2d(8, 8, 1),  # 1x1 Âç∑ÁßØÔºå‰øùÊåÅÈÄöÈÅìÊï∞‰∏∫8\n",
    "        )\n",
    "\n",
    "        # ÂÆö‰πâËß£Á†ÅÂô®ÈÉ®ÂàÜ\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            # ËæìÂÖ•Â±ÇÔºö‰ªéÊ≠£ÊÄÅÂàÜÂ∏É‰∏≠ÈááÊ†∑ÂæóÂà∞ÁöÑ4‰∏™ÈÄöÈÅì\n",
    "            torch.nn.Conv2d(4, 4, 1),  # 1x1 Âç∑ÁßØÔºå‰øùÊåÅÈÄöÈÅìÊï∞‰∏∫4\n",
    "\n",
    "            # ÂàùÂßãÂç∑ÁßØÊìç‰ΩúÔºåÂ∞ÜÈÄöÈÅìÊï∞‰ªé4Âèò‰∏∫512\n",
    "            torch.nn.Conv2d(4, 512, kernel_size=3, stride=1, padding=1),\n",
    "\n",
    "            # ‰∏≠Èó¥ÈÉ®ÂàÜÔºöResNet Ê®°ÂùóÂíåÊ≥®ÊÑèÂäõÊú∫Âà∂\n",
    "            torch.nn.Sequential(Resnet(512, 512), Atten(), Resnet(512, 512)),\n",
    "\n",
    "            # ‰∏äÈááÊ†∑ÈÉ®ÂàÜÔºàÂ§öÂ±Ç ResNet Ê®°ÂùóÂíå‰∏äÈááÊ†∑Êìç‰ΩúÔºâ\n",
    "            torch.nn.Sequential(\n",
    "                Resnet(512, 512),  # ResNet Ê®°ÂùóÔºå‰øùÊåÅÈÄöÈÅìÊï∞‰∏∫512\n",
    "                Resnet(512, 512),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "                Resnet(512, 512),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "                torch.nn.Upsample(scale_factor=2.0, mode='nearest'),  # ‰∏äÈááÊ†∑ÔºåÁâπÂæÅÂõæÂ∞∫ÂØ∏Âä†ÂÄç\n",
    "                torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),  # Âç∑ÁßØÔºå‰øùÊåÅÈÄöÈÅìÊï∞‰∏∫512\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                Resnet(512, 512),  # ResNet Ê®°ÂùóÔºå‰øùÊåÅÈÄöÈÅìÊï∞‰∏∫512\n",
    "                Resnet(512, 512),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "                Resnet(512, 512),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "                torch.nn.Upsample(scale_factor=2.0, mode='nearest'),  # ‰∏äÈááÊ†∑ÔºåÁâπÂæÅÂõæÂ∞∫ÂØ∏Âä†ÂÄç\n",
    "                torch.nn.Conv2d(512, 512, kernel_size=3, padding=1),  # Âç∑ÁßØÔºå‰øùÊåÅÈÄöÈÅìÊï∞‰∏∫512\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                Resnet(512, 256),  # ResNet Ê®°ÂùóÔºåÂ∞ÜÈÄöÈÅìÊï∞‰ªé512Âáè‰∏∫256\n",
    "                Resnet(256, 256),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "                Resnet(256, 256),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "                torch.nn.Upsample(scale_factor=2.0, mode='nearest'),  # ‰∏äÈááÊ†∑ÔºåÁâπÂæÅÂõæÂ∞∫ÂØ∏Âä†ÂÄç\n",
    "                torch.nn.Conv2d(256, 256, kernel_size=3, padding=1),  # Âç∑ÁßØÔºå‰øùÊåÅÈÄöÈÅìÊï∞‰∏∫256\n",
    "            ),\n",
    "            torch.nn.Sequential(\n",
    "                Resnet(256, 128),  # ResNet Ê®°ÂùóÔºåÂ∞ÜÈÄöÈÅìÊï∞‰ªé256Âáè‰∏∫128\n",
    "                Resnet(128, 128),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "                Resnet(128, 128),  # ÂÜçÊ¨°ÈÄöËøá ResNet Ê®°Âùó\n",
    "            ),\n",
    "\n",
    "            # ËæìÂá∫Â±ÇÔºöÊ†áÂáÜÂåñÂíåÂç∑ÁßØÊìç‰Ωú\n",
    "            torch.nn.Sequential(\n",
    "                torch.nn.GroupNorm(num_channels=128, num_groups=32, eps=1e-6),  # ÁªÑÂΩí‰∏ÄÂåñ\n",
    "                torch.nn.SiLU(),  # SiLU ÊøÄÊ¥ªÂáΩÊï∞\n",
    "                torch.nn.Conv2d(128, 3, 3, padding=1),  # Â∞ÜÈÄöÈÅìÊï∞Èôç‰∏∫3ÔºåÂç≥ÊÅ¢Â§ç‰∏∫RGBÂõæÂÉè\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    # ÈááÊ†∑ÂáΩÊï∞Ôºå‰ªéÊ≠£ÊÄÅÂàÜÂ∏É‰∏≠ÁîüÊàêÊñ∞ÁöÑÊï∞ÊçÆ\n",
    "    def sample(self, h):\n",
    "        # h -> [1, 8, 64, 64]\n",
    "\n",
    "        # Â∞ÜÁâπÂæÅÂõæÁöÑÂâç4‰∏™ÈÄöÈÅì‰Ωú‰∏∫ÂùáÂÄºÔºåÂêé4‰∏™ÈÄöÈÅì‰Ωú‰∏∫ÊñπÂ∑Æ\n",
    "        mean = h[:, :4]\n",
    "        logvar = h[:, 4:]\n",
    "        std = logvar.exp() ** 0.5  # ËÆ°ÁÆóÊ†áÂáÜÂ∑Æ\n",
    "\n",
    "        # ‰ªéÊ≠£ÊÄÅÂàÜÂ∏É‰∏≠ÈááÊ†∑ÔºåÂπ∂‰ΩøÁî®ÈáçÂèÇÊï∞ÊäÄÂ∑ßÁîüÊàêÊñ∞ÁöÑÁâπÂæÅÂõæ\n",
    "        h = torch.randn(mean.shape, device=mean.device)\n",
    "        h = mean + std * h\n",
    "\n",
    "        # ËøîÂõûÁ¨¶ÂêàÊ≠£ÊÄÅÂàÜÂ∏ÉÁöÑ h\n",
    "        return h\n",
    "\n",
    "    # ÂâçÂêë‰º†Êí≠ÂáΩÊï∞\n",
    "    def forward(self, x):\n",
    "        # üëá 1 Ë°®Á§∫‰∏ÄÂº†ÂõæÁâá\n",
    "        # x -> [1, 3, 512, 512]\n",
    "\n",
    "        # ÁºñÁ†ÅÔºöÂ∞ÜËæìÂÖ•ÂõæÂÉèÁºñÁ†Å‰∏∫ÈöêÂèòÈáè\n",
    "        h = self.encoder(x)  # h -> [1, 8, 64, 64]\n",
    "\n",
    "        # ‰ªéÈöêÂèòÈáè‰∏≠ÈááÊ†∑\n",
    "        h = self.sample(h)  # h -> [1, 4, 64, 64]\n",
    "\n",
    "        # Ëß£Á†ÅÔºöÂ∞ÜÈöêÂèòÈáèËß£Á†Å‰∏∫ÂõæÂÉè\n",
    "        h = self.decoder(h)  # h -> [1, 3, 512, 512]\n",
    "\n",
    "        return h  # ËøîÂõûÈáçÂª∫ÁöÑÂõæÂÉè\n",
    "\n",
    "# ÊµãËØï VAE Ê®°Âûã\n",
    "VAE()(torch.randn(1, 3, 512, 512)).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeno/mambaforge/envs/torch_gpu_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "The config attributes {'scaling_factor': 0.18215} were passed to AutoencoderKL, but are not expected and will be ignored. Please verify your config.json configuration file.\n",
      "/Users/zeno/mambaforge/envs/torch_gpu_env/lib/python3.9/site-packages/diffusers/models/modeling_utils.py:99: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_attention_op', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_use_memory_efficient_attention_xformers', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'channels', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'group_norm', 'half', 'ipu', 'key', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'num_head_size', 'num_heads', 'parameters', 'proj_attn', 'query', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'rescale_output_factor', 'reshape_batch_dim_to_heads', 'reshape_heads_to_batch_dim', 'set_extra_state', 'set_use_memory_efficient_attention_xformers', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'value', 'xpu', 'zero_grad']\n",
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_attention_op', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_use_memory_efficient_attention_xformers', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bfloat16', 'buffers', 'call_super_init', 'channels', 'children', 'compile', 'cpu', 'cuda', 'double', 'dump_patches', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'group_norm', 'half', 'ipu', 'key', 'load_state_dict', 'modules', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'num_head_size', 'num_heads', 'parameters', 'proj_attn', 'query', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_module', 'register_parameter', 'register_state_dict_pre_hook', 'requires_grad_', 'rescale_output_factor', 'reshape_batch_dim_to_heads', 'reshape_heads_to_batch_dim', 'set_extra_state', 'set_use_memory_efficient_attention_xformers', 'share_memory', 'state_dict', 'to', 'to_empty', 'train', 'training', 'type', 'value', 'xpu', 'zero_grad']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Âä†ËΩΩ„ÄêÈ¢ÑËÆ≠ÁªÉÊ®°Âûã„ÄëÊù•ÂàùÂßãÂåñÂèÇÊï∞\n",
    "from diffusers import AutoencoderKL\n",
    "\n",
    "#Âä†ËΩΩÈ¢ÑËÆ≠ÁªÉÊ®°ÂûãÁöÑÂèÇÊï∞\n",
    "params = AutoencoderKL.from_pretrained(\n",
    "    'model/diffsion_from_scratch.params', subfolder='vae')\n",
    "\n",
    "vae = VAE()\n",
    "\n",
    "# Âä†ËΩΩÂèÇÊï∞Áî®ÁöÑÂáΩÊï∞\n",
    "def load_res(model, param):\n",
    "    model.s[0].load_state_dict(param.norm1.state_dict())\n",
    "    model.s[2].load_state_dict(param.conv1.state_dict())\n",
    "    model.s[3].load_state_dict(param.norm2.state_dict())\n",
    "    model.s[5].load_state_dict(param.conv2.state_dict())\n",
    "\n",
    "    if isinstance(model.res, torch.nn.Module):\n",
    "        model.res.load_state_dict(param.conv_shortcut.state_dict())\n",
    "\n",
    "# Âä†ËΩΩÂèÇÊï∞Áî®ÁöÑÂáΩÊï∞\n",
    "def load_atten(model, param):\n",
    "    print(dir(param)) \n",
    "    model.norm.load_state_dict(param.group_norm.state_dict())\n",
    "    model.q.load_state_dict(param.query.state_dict())\n",
    "    model.k.load_state_dict(param.key.state_dict())\n",
    "    model.v.load_state_dict(param.value.state_dict())\n",
    "    model.out.load_state_dict(param.proj_attn.state_dict())\n",
    "\n",
    "\n",
    "#encoder.in\n",
    "vae.encoder[0].load_state_dict(params.encoder.conv_in.state_dict())\n",
    "\n",
    "#encoder.down\n",
    "for i in range(4):\n",
    "    load_res(vae.encoder[i + 1][0], params.encoder.down_blocks[i].resnets[0])\n",
    "    load_res(vae.encoder[i + 1][1], params.encoder.down_blocks[i].resnets[1])\n",
    "\n",
    "    if i != 3:\n",
    "        vae.encoder[i + 1][2][1].load_state_dict(\n",
    "            params.encoder.down_blocks[i].downsamplers[0].conv.state_dict())\n",
    "\n",
    "#encoder.mid\n",
    "load_res(vae.encoder[5][0], params.encoder.mid_block.resnets[0])\n",
    "load_res(vae.encoder[5][2], params.encoder.mid_block.resnets[1])\n",
    "load_atten(vae.encoder[5][1], params.encoder.mid_block.attentions[0])\n",
    "\n",
    "#encoder.out\n",
    "vae.encoder[6][0].load_state_dict(params.encoder.conv_norm_out.state_dict())\n",
    "vae.encoder[6][2].load_state_dict(params.encoder.conv_out.state_dict())\n",
    "\n",
    "#encoder.Ê≠£ÊÄÅÂàÜÂ∏ÉÂ±Ç\n",
    "vae.encoder[7].load_state_dict(params.quant_conv.state_dict())\n",
    "\n",
    "#decoder.Ê≠£ÊÄÅÂàÜÂ∏ÉÂ±Ç\n",
    "vae.decoder[0].load_state_dict(params.post_quant_conv.state_dict())\n",
    "\n",
    "#decoder.in\n",
    "vae.decoder[1].load_state_dict(params.decoder.conv_in.state_dict())\n",
    "\n",
    "#decoder.mid\n",
    "load_res(vae.decoder[2][0], params.decoder.mid_block.resnets[0])\n",
    "load_res(vae.decoder[2][2], params.decoder.mid_block.resnets[1])\n",
    "load_atten(vae.decoder[2][1], params.decoder.mid_block.attentions[0])\n",
    "\n",
    "#decoder.up\n",
    "for i in range(4):\n",
    "    load_res(vae.decoder[i + 3][0], params.decoder.up_blocks[i].resnets[0])\n",
    "    load_res(vae.decoder[i + 3][1], params.decoder.up_blocks[i].resnets[1])\n",
    "    load_res(vae.decoder[i + 3][2], params.decoder.up_blocks[i].resnets[2])\n",
    "\n",
    "    if i != 3:\n",
    "        vae.decoder[i + 3][4].load_state_dict(\n",
    "            params.decoder.up_blocks[i].upsamplers[0].conv.state_dict())\n",
    "\n",
    "#decoder.out\n",
    "vae.decoder[7][0].load_state_dict(params.decoder.conv_norm_out.state_dict())\n",
    "vae.decoder[7][2].load_state_dict(params.decoder.conv_out.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ÊµãËØï encode\n",
    "data = torch.randn(1, 3, 512, 512)\n",
    "\n",
    "a = vae.encoder(data)\n",
    "b = params.encode(data).latent_dist.parameters\n",
    "\n",
    "(a == b).all() # tensor(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ÊµãËØï decode\n",
    "data = torch.randn(1, 4, 64, 64)\n",
    "\n",
    "a = vae.decoder(data)\n",
    "b = params.decode(data).sample\n",
    "\n",
    "(a == b).all() # tensor(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
